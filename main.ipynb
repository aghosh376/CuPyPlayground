{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y locales\n",
        "!locale-gen en_US.UTF-8\n",
        "!update-locale LANG=en_US.UTF-8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKJlNQ92d3pJ",
        "outputId": "31e2afb2-8e6f-4291-bf09-66031815a901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Connecting to security.ubuntu.com (185.125.1\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Connecting to security.ubuntu.com (185.125.1\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)]\r                                                                                                    \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Ign:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,586 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,159 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,355 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,447 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,318 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,596 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [53.5 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.7 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [81.4 kB]\n",
            "Fetched 19.0 MB in 3s (6,688 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "locales is already the newest version (2.35-0ubuntu3.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 54 not upgraded.\n",
            "Generating locales (this might take a while)...\n",
            "  en_US.UTF-8... done\n",
            "Generation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env -qU\n",
        "import colab_env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYb9hdbIdkhH",
        "outputId": "6a41a018-e716-45e5-8e18-cf07677ca6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Mounted at /content/gdrive\n",
            "Creating vars.env in your Google Drive!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "\n",
        "import os\n",
        "\n",
        "import dotenv\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dotenv.load_dotenv('/content/drive/MyDrive/cupy.env')\n",
        "\n",
        "os.environ.get('CUDA_ACCELERATOR')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "1Yy1NdVub4et",
        "outputId": "61e5e29f-dd0f-46fc-abf9-d3aaa1c7a5bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cutensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.environ.get('CUDA_ACCELERATOR'))"
      ],
      "metadata": {
        "id": "L4l6_GmTXP2f",
        "outputId": "d653f766-9bd9-4f6e-e0cb-adffc643c4d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cutensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cupy-cuda12x cutensor-cu12"
      ],
      "metadata": {
        "id": "et1VREDSRbdJ",
        "outputId": "4b54eefc-752f-4641-c07a-c31363306c56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.10/dist-packages (12.2.0)\n",
            "Collecting cutensor-cu12\n",
            "  Downloading cutensor_cu12-2.0.2-py3-none-manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy<1.27,>=1.20 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x) (1.26.4)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x) (0.8.2)\n",
            "Downloading cutensor_cu12-2.0.2-py3-none-manylinux2014_x86_64.whl (156.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.9/156.9 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cutensor-cu12\n",
            "Successfully installed cutensor-cu12-2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PCQA_qVbdatJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "import cutensor as cutensor\n",
        "\n",
        "cp.cuda.Stream.null.synchronize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b2ku3jJvdatL"
      },
      "outputs": [],
      "source": [
        "arr = cp.ones((1000,500,500))\n",
        "\n",
        "#makes us wait for gpu to finish before returning\n",
        "cp.cuda.Stream.null.synchronize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OQ2IjmbodatL",
        "outputId": "ac892a5b-23b7-4702-f8a2-09083d3007a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A:  [[[ 1  2  3]\n",
            "  [ 3  4  5]\n",
            "  [ 6  7  8]]\n",
            "\n",
            " [[ 9 10 11]\n",
            "  [12 13 14]\n",
            "  [15 16 17]]]\n",
            "B:  [[[0.89037304 0.51555246 0.74820862]\n",
            "  [0.85194354 0.51516188 0.93383825]\n",
            "  [0.40876618 0.98815755 0.14175375]]\n",
            "\n",
            " [[0.41463821 0.25768896 0.26773643]\n",
            "  [0.90078436 0.60219592 0.7972908 ]\n",
            "  [0.82448646 0.2639169  0.23354816]]\n",
            "\n",
            " [[0.31462561 0.01686404 0.67710199]\n",
            "  [0.46265903 0.6170781  0.86759747]\n",
            "  [0.32030822 0.70509691 0.65776888]]]\n",
            "(2, 3, 3)\n",
            "(3, 3, 3)\n"
          ]
        }
      ],
      "source": [
        "A = cp.array([[[1,2,3],\n",
        "               [3,4,5],\n",
        "               [6,7,8]],\n",
        "\n",
        "              [[9,10,11],\n",
        "               [12,13,14],\n",
        "               [15,16,17]]],)\n",
        "\n",
        "B = cp.random.rand(3,3,3)\n",
        "\n",
        "\n",
        "print(\"A: \", A)\n",
        "print(\"B: \", B)\n",
        "print(A.shape)\n",
        "print(B.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1dTdg8HdatM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebb2766-901f-4989-cee1-5bd8a74dcdb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with cp.einsum:  [[17.63499399 16.34839075 23.61003662]\n",
            " [53.88210597 54.03773114 65.03892462]]\n"
          ]
        }
      ],
      "source": [
        "result = cp.einsum('ijk,jkl->il', A, B)\n",
        "print(\"Result with cp.einsum: \", result)\n",
        "\n",
        "# ijk the dimensions of A, jkl the dimensions of B, il the dimensions of the einstein sum\n",
        "# contraction happens over the j and k dimensions\n",
        "cp.cuda.Stream.null.synchronize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdKNi8kEdatM",
        "outputId": "cf3d9f4e-f37e-464c-9392-c9e30627472b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'cutensor' has no attribute 'create_tensor_descriptor'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8bd187529094>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#need descriptors to describe shape, data type and memory of tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdesc_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcutensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_tensor_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdesc_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcutensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_tensor_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'cutensor' has no attribute 'create_tensor_descriptor'"
          ]
        }
      ],
      "source": [
        "# using cutensor\n",
        "\n",
        "#need descriptors to describe shape, data type and memory of tensor\n",
        "desc_A = cutensor.create_tensor_descriptor(A)\n",
        "\n",
        "desc_B = cutensor.create_tensor_descriptor(B)\n",
        "\n",
        "# Empty output tensor of the shape of the einstein sum of dimensions il\n",
        "output = cp.empty((2,3), dType = A.dtype)\n",
        "\n",
        "desc_output = cutensor.create_tensor_descriptor(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vHtf1bKdatM"
      },
      "outputs": [],
      "source": [
        "#create description of contraction of the tensors\n",
        "contract_desc = cutensor.einsum_expr(('i','j','k'),('j','k','l'),('i','l'))\n",
        "#('i','j','k') dimensions of A,\n",
        "#('j','k','l') dimensions of B,\n",
        "#('i','l') dimensions of output\n",
        "\n",
        "#scale factor for contraction operation\n",
        "alpha = 1.0\n",
        "#scale factor for output\n",
        "beta = 0.0\n",
        "\n",
        "#contraction plan\n",
        "contraction_plan = cutensor.create_contraction_plan(contract_desc, desc_A, desc_B, desc_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LPLkOR2datM"
      },
      "outputs": [],
      "source": [
        "#Perform contraction using contraction plan\n",
        "cutensor.contraction(contraction_plan, alpha, A, desc_A, B, desc_B, beta, output, desc_output)\n",
        "\n",
        "cp.cuda.Stream.null.synchronise()\n",
        "print(\"Result with cutensor: \", output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Task 1 function/abstract contraction passing the tensor, matrix, and dimension\n",
        "\n",
        "def contract(A, X, dim):\n",
        "    # Takes tensor A of unknown number of dimensions\n",
        "    # Takes matrix h with 2 dimensions Kk\n",
        "    # Takes int dim as the dimension to contract over\n",
        "    if (type(dim) != int and type(dim) == str) :\n",
        "      raise ValueError(f\"Dim must be an int not a string\")\n",
        "\n",
        "    # Get the dimensions of the tensor and matrix\n",
        "    A_shape = cp.array(A.shape)\n",
        "    X_shape = cp.array(X.shape)\n",
        "\n",
        "    # Check that the size of the dimension matches\n",
        "    if A_shape[dim] != X_shape[1]:\n",
        "      raise ValueError(f\"Dimension mismatch: A has size {A_shape[dim]} along dimension {dim}, \"f\"but X has size {X_shape[1]}\")\n",
        "\n",
        "    # Compress the dimensions not involved in contraction\n",
        "\n",
        "    reshape_left = cp.prod(A_shape[:dim]).item()\n",
        "    contract_dim_size = A_shape[dim].item()\n",
        "    reshape_right = cp.prod(A_shape[dim+1:]).item()\n",
        "\n",
        "    #print(f\"Reshape Left: {reshape_left} (type: {type(reshape_left)})\")\n",
        "    #print(f\"Contract Dim Size: {contract_dim_size} (type: {type(contract_dim_size)})\")\n",
        "    #print(f\"Reshape Right: {reshape_right} (type: {type(reshape_right)})\")\n",
        "\n",
        "\n",
        "    As = A.reshape(reshape_left, contract_dim_size, reshape_right)\n",
        "\n",
        "    result = cp.einsum(\"jkl, Kk->jKl\", As, X)\n",
        "    #print(*A_shape[:dim].tolist(), X.shape[0], *A_shape[dim + 1:].tolist())\n",
        "    result = result.reshape(*A_shape[:dim].tolist(), X.shape[0], *A_shape[dim + 1:].tolist())\n",
        "\n",
        "    return result\n",
        "\n",
        "    #As = A.reshape( np.prod(A.shape[:2]), A.shape[2], np.prod(A.shape[3:]))\n",
        "    #Ahs = np.einsum(\"Kk,ikl->iKl\",h,As)\n",
        "    #np.allclose(Ahs.ravel(),Ah.ravel())\n",
        "#\n",
        "#\n",
        "    #In [17]: A = np.random.rand(3,2,4,6,1)\n",
        "\n",
        "    #In [18]: h = np.random.rand(4,4)\n",
        "\n",
        "    #In [19]: Ah = np.einsum(\"Kk,ijklm->ijKlm\",h,A)\n",
        "\n",
        "    #In [20]: As = A.reshape( np.prod(A.shape[:2]), A.shape[2],\n",
        "    #np.prod(A.shape[3:]))\n",
        "\n",
        "    #In [21]: Ahs = np.einsum(\"Kk,ikl->iKl\",h,As)\n",
        "\n",
        "    #In [22]: np.allclose(Ahs.ravel(),Ah.ravel())\n",
        "    #In [23]: np.allclose(Ahs.reshape(Ah.shape),Ah)\n",
        "#\n",
        "    #A = A.reshape(A.prod(A.shape[:]))\n",
        "\n"
      ],
      "metadata": {
        "id": "sXI3F2gfx98d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.random.rand(2,3,2,4,7,8)\n",
        "h = np.random.rand(4,7)\n",
        "Ah = np.einsum(\"Kk,hijlkm->hijlKm\",h,A)\n",
        "\n",
        "Ahs = contract(A, h, 4)\n",
        "\n",
        "print(cp.allclose(Ahs.ravel(),Ah.ravel()))\n",
        "print(len(Ahs.ravel()))\n",
        "print(len(Ah.ravel()))\n",
        "print(cp.allclose(Ahs.reshape(Ah.shape),Ah))\n",
        "print(cp.allclose(Ahs,Ah))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLtXH2PE7pA2",
        "outputId": "05391246-3d2d-4bb8-c9ad-e77633d3fe38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1536\n",
            "1536\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.random.rand(2,7,8)\n",
        "h = np.random.rand(4,7)\n",
        "Ah = np.einsum(\"Kk,hkm->hKm\",h,A)\n",
        "\n",
        "Ahs = contract(A, h, 1)\n",
        "print(Ahs, \" hs\")\n",
        "print(Ah)"
      ],
      "metadata": {
        "id": "bjUd6Mnq7-2f",
        "outputId": "39d07994-0c84-4bad-cf2d-d883c599c6fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[1.89546492 0.99920597 1.65559785 1.28241343 1.63012005 1.03819686\n",
            "   1.01573991 2.23023089]\n",
            "  [2.41601511 1.47243827 2.03740346 1.81542522 2.65966053 1.77995681\n",
            "   1.52068415 2.71345123]\n",
            "  [1.6024132  0.83898067 1.21026019 0.88208145 1.19474929 0.81318585\n",
            "   1.01715205 1.7361451 ]\n",
            "  [2.2648725  1.24998627 1.33162126 1.07031665 2.08061963 1.27806666\n",
            "   1.73700466 2.19160274]]\n",
            "\n",
            " [[1.92945463 1.67204674 2.73611767 1.27540545 1.26966615 1.47690926\n",
            "   1.38953016 2.24160723]\n",
            "  [1.85853126 2.3912412  3.37542082 2.03904117 1.54999492 2.28167553\n",
            "   1.54723588 2.79278733]\n",
            "  [1.51175611 1.46333623 1.88953545 0.89352247 1.01780147 0.9705407\n",
            "   0.9917775  1.56028492]\n",
            "  [1.75181629 2.39890555 2.19394754 1.24637391 1.42086027 1.40715606\n",
            "   1.17433515 1.97622764]]]  hs\n",
            "[[[1.89546492 0.99920597 1.65559785 1.28241343 1.63012005 1.03819686\n",
            "   1.01573991 2.23023089]\n",
            "  [2.41601511 1.47243827 2.03740346 1.81542522 2.65966053 1.77995681\n",
            "   1.52068415 2.71345123]\n",
            "  [1.6024132  0.83898067 1.21026019 0.88208145 1.19474929 0.81318585\n",
            "   1.01715205 1.7361451 ]\n",
            "  [2.2648725  1.24998627 1.33162126 1.07031665 2.08061963 1.27806666\n",
            "   1.73700466 2.19160274]]\n",
            "\n",
            " [[1.92945463 1.67204674 2.73611767 1.27540545 1.26966615 1.47690926\n",
            "   1.38953016 2.24160723]\n",
            "  [1.85853126 2.3912412  3.37542082 2.03904117 1.54999492 2.28167553\n",
            "   1.54723588 2.79278733]\n",
            "  [1.51175611 1.46333623 1.88953545 0.89352247 1.01780147 0.9705407\n",
            "   0.9917775  1.56028492]\n",
            "  [1.75181629 2.39890555 2.19394754 1.24637391 1.42086027 1.40715606\n",
            "   1.17433515 1.97622764]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "import time\n",
        "from cupy import cutensor as cutensor\n",
        "\n",
        "cp.cuda.Stream.null.synchronize()\n",
        "\n",
        "\n",
        "#arr = cp.ones((1000,500,500))\n",
        "\n",
        "#makes us wait for gpu to finish before returning\n",
        "cp.cuda.Stream.null.synchronize()\n",
        "\n",
        "\n",
        "#A = cp.array([[[1,2,3],\n",
        "#               [3,4,5],\n",
        "#               [6,7,8]],\n",
        "#\n",
        "#              [[9,10,11],\n",
        "#               [12,13,14],\n",
        "#               [15,16,17]]],)\n",
        "\n",
        "#B = cp.random.rand(3,3,3)\n",
        "\n",
        "\n",
        "#print(\"A: \", A)\n",
        "#print(\"B: \", B)\n",
        "#print(A.shape)\n",
        "#print(B.shape)\n",
        "\n",
        "\n",
        "def contract(A, X, dim):\n",
        "    # Takes tensor A of unknown number of dimensions\n",
        "    # Takes matrix h with 2 dimensions Kk\n",
        "    # Takes int dim as the dimension to contract over\n",
        "    if (type(dim) != int and type(dim) == str) :\n",
        "      raise ValueError(f\"Dim must be an int not a string\")\n",
        "\n",
        "    # Get the dimensions of the tensor and matrix\n",
        "    A_shape = cp.array(A.shape)\n",
        "    X_shape = cp.array(X.shape)\n",
        "\n",
        "    # Check that the size of the dimension matches\n",
        "    if A_shape[dim] != X_shape[1]:\n",
        "      raise ValueError(f\"Dimension mismatch: A has size {A_shape[dim]} along dimension {dim}, \"f\"but X has size {X_shape[1]}\")\n",
        "\n",
        "    # Compress the dimensions not involved in contraction\n",
        "\n",
        "    reshape_left = cp.prod(A_shape[:dim]).item()\n",
        "    contract_dim_size = A_shape[dim].item()\n",
        "    reshape_right = cp.prod(A_shape[dim+1:]).item()\n",
        "\n",
        "    #print(f\"Reshape Left: {reshape_left} (type: {type(reshape_left)})\")\n",
        "    #print(f\"Contract Dim Size: {contract_dim_size} (type: {type(contract_dim_size)})\")\n",
        "    #print(f\"Reshape Right: {reshape_right} (type: {type(reshape_right)})\")\n",
        "\n",
        "    As = A.reshape(reshape_left, contract_dim_size, reshape_right)\n",
        "\n",
        "    result = cp.einsum(\"jkl, Kk->jKl\", As, X)\n",
        "    #print(*A_shape[:dim].tolist(), X.shape[0], *A_shape[dim + 1:].tolist())\n",
        "    result = result.reshape(*A_shape[:dim].tolist(), X.shape[0], *A_shape[dim + 1:].tolist())\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def contract_with_plan(A, X, dim):\n",
        "    if (type(dim) != int and type(dim) == str) :\n",
        "        raise ValueError(f\"Dim must be an int not a string\")\n",
        "\n",
        "    A_shape = cp.array(A.shape)\n",
        "    X_shape = cp.array(X.shape)\n",
        "\n",
        "    if A_shape[dim] != X_shape[1]:\n",
        "      raise ValueError(f\"Dimension mismatch: A has size {A_shape[dim]} along dimension {dim}, \"f\"but X has size {X_shape[1]}\")\n",
        "\n",
        "\n",
        "    A_dims = len(A_shape)\n",
        "    X_dims = len(X_shape)\n",
        "\n",
        "    if X_dims > 2:\n",
        "        raise ValueError(f\"Contractiong matrix has {X_dims} dimensions when it should only have 2\")\n",
        "\n",
        "    A_mode = tuple(map(chr, range(97, 97 + A_dims)))\n",
        "    X_mode = tuple(chr(97 + A_dims), A_mode[dim])\n",
        "\n",
        "    result_mode = tuple(A_mode[:dim] + X_mode[0] + A_mode[dim+1:])\n",
        "    result_shape = A_shape[:dim] + X_shape[0] + A_shape[dim+1:]\n",
        "    result_empty = cp.empty(result_shape)\n",
        "\n",
        "    alpha = 1.0\n",
        "    beta = 0.0\n",
        "    result = cutensor.contraction(alpha, A, A_mode, X, X_mode, beta, result_empty, result_mode)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "alpha = 1.0\n",
        "beta = 0.0\n",
        "mode_a = ('a', 'b', 'c')\n",
        "mode_b = ('d', 'b')\n",
        "mode_c = ('d', 'e')\n",
        "mode_ab = ('a','d', 'c')\n",
        "mode_abc = ('a', 'e')\n",
        "a = cp.random.random((3, 4, 5))\n",
        "b = cp.random.random((6, 4))\n",
        "c = cp.random.random((6, 7))\n",
        "ab = cp.empty((3, 6, 5))\n",
        "abc = cp.empty((3, 7))\n",
        "\n",
        "result_AB = cutensor.contraction(alpha, a, mode_a, b, mode_b, beta, ab, mode_ab)\n",
        "\n",
        "result_AB_func = contract_with_plan(a, b, 1)\n",
        "\n",
        "cp.cuda.Stream.null.synchronize()\n",
        "\n",
        "print(cp.allclose(result_AB, result_AB_func))\n",
        "\n",
        "#cutensor.contraction(alpha, ab, mode_ab, c, mode_c, beta, abc, mode_abc)\n",
        "#\n",
        "#cp.cuda.Stream.null.synchronize()\n",
        "#\n",
        "#\n",
        "#size = A.data.nybytes\n",
        "\n",
        "#print(result_AB)\n",
        "#print(contract(a, b, 1))\n",
        "\n",
        "#twrite = []\n",
        "#for i in range(10):\n",
        "#    a = cp.random.random((3, 4, 5))\n",
        "#    b = cp.random.random((6, 4))\n",
        "#    ab = cp.empty(3,6,5)\n",
        "#    t1 = time.time()\n",
        "#    result_AB_func = contract_with_plan(a, b, 1)\n",
        "#    cp.cuda.Stream.null.synchronize()\n",
        "#    t1 = time.time() - t1\n",
        "#    twrite.append(t1)\n",
        "#\n",
        "#times = np.array(twrite)\n",
        "\n",
        "#print(f\"\\tWRITE  mean= {times.mean():12.5f} max= {times.max():12.5f} min= {times.min():12.5f} std= {times.std():12.5f}\",flush=True)\n"
      ],
      "metadata": {
        "id": "YrwQnQTdcfqN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}